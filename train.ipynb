{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emoji prediction based on text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdulmunim\\AppData\\Local\\Temp\\ipykernel_12092\\2654145384.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Abdulmunim\\Desktop\\Dallol-i Projects\\emojitron\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, SimpleRNN, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French macaroon is so tasty</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>work is horrible</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am upset</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>throw the ball</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good joke</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0  1\n",
       "0  French macaroon is so tasty  4\n",
       "1             work is horrible  3\n",
       "2                   I am upset  3\n",
       "3               throw the ball  1\n",
       "4                    Good joke  2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/emoji_data.csv', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dict = {\n",
    "    0: \":red_heart:\",\n",
    "    1: \":baseball:\",\n",
    "    2: \":grinning_face_with_big_eyes:\",\n",
    "    3: \":disappointed_face:\",\n",
    "    4: \":fork_and_knife_with_plate:\"\n",
    "}\n",
    "\n",
    "\n",
    "def label_to_emoji(label):\n",
    "    return emoji.emojize(emoji_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[0].values\n",
    "y = data[1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the 0.418 0.24968 -0.41242 0.1217 0.34527 -0.044457 -0.49688 -0.17862 -0.00066023 -0.6566 0.27843 -0.14767 -0.55677 0.14658 -0.0095095 0.011658 0.10204 -0.12792 -0.8443 -0.12181 -0.016801 -0.33279 -0.1552 -0.23131 -0.19181 -1.8823 -0.76746 0.099051 -0.42125 -0.19526 4.0071 -0.18594 -0.52287 -0.31681 0.00059213 0.0074449 0.17778 -0.15897 0.012041 -0.054223 -0.29871 -0.15749 -0.34758 -0.045637 -0.44251 0.18785 0.0027849 -0.18411 -0.11514 -0.78581\\n',\n",
       " ', 0.013441 0.23682 -0.16899 0.40951 0.63812 0.47709 -0.42852 -0.55641 -0.364 -0.23938 0.13001 -0.063734 -0.39575 -0.48162 0.23291 0.090201 -0.13324 0.078639 -0.41634 -0.15428 0.10068 0.48891 0.31226 -0.1252 -0.037512 -1.5179 0.12612 -0.02442 -0.042961 -0.28351 3.5416 -0.11956 -0.014533 -0.1499 0.21864 -0.33412 -0.13872 0.31806 0.70358 0.44858 -0.080262 0.63003 0.32111 -0.46765 0.22786 0.36034 -0.37818 -0.56657 0.044691 0.30392\\n',\n",
       " '. 0.15164 0.30177 -0.16763 0.17684 0.31719 0.33973 -0.43478 -0.31086 -0.44999 -0.29486 0.16608 0.11963 -0.41328 -0.42353 0.59868 0.28825 -0.11547 -0.041848 -0.67989 -0.25063 0.18472 0.086876 0.46582 0.015035 0.043474 -1.4671 -0.30384 -0.023441 0.30589 -0.21785 3.746 0.0042284 -0.18436 -0.46209 0.098329 -0.11907 0.23919 0.1161 0.41705 0.056763 -6.3681e-05 0.068987 0.087939 -0.10285 -0.13931 0.22314 -0.080803 -0.35652 0.016413 0.10216\\n',\n",
       " 'of 0.70853 0.57088 -0.4716 0.18048 0.54449 0.72603 0.18157 -0.52393 0.10381 -0.17566 0.078852 -0.36216 -0.11829 -0.83336 0.11917 -0.16605 0.061555 -0.012719 -0.56623 0.013616 0.22851 -0.14396 -0.067549 -0.38157 -0.23698 -1.7037 -0.86692 -0.26704 -0.2589 0.1767 3.8676 -0.1613 -0.13273 -0.68881 0.18444 0.0052464 -0.33874 -0.078956 0.24185 0.36576 -0.34727 0.28483 0.075693 -0.062178 -0.38988 0.22902 -0.21617 -0.22562 -0.093918 -0.80375\\n',\n",
       " 'to 0.68047 -0.039263 0.30186 -0.17792 0.42962 0.032246 -0.41376 0.13228 -0.29847 -0.085253 0.17118 0.22419 -0.10046 -0.43653 0.33418 0.67846 0.057204 -0.34448 -0.42785 -0.43275 0.55963 0.10032 0.18677 -0.26854 0.037334 -2.0932 0.22171 -0.39868 0.20912 -0.55725 3.8826 0.47466 -0.95658 -0.37788 0.20869 -0.32752 0.12751 0.088359 0.16351 -0.21634 -0.094375 0.018324 0.21048 -0.03088 -0.19722 0.082279 -0.09434 -0.073297 -0.064699 -0.26044\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will use 50d pretrained embeddings\n",
    "content = []\n",
    "with open(\"pretrained/glove.6B.50d.txt\", 'r', encoding='utf-8') as f:\n",
    "    content = f.readlines()\n",
    "content[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "\n",
    "for line in content:\n",
    "    line = line.split()\n",
    "    word, vector = line[0], np.array(line[1:], dtype=float)\n",
    "    embeddings[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maxlen(X):\n",
    "    maxlen = 0\n",
    "    for sentence in X:\n",
    "        maxlen = max(maxlen, len(sentence))\n",
    "    return maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "word2index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[103, 104, 3, 6, 105], [106, 3, 107], [1, 7, 108], [109, 4, 35], [36, 30]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "X_seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = get_maxlen(X_seq)\n",
    "X_seq_padded = pad_sequences(\n",
    "    X_seq, maxlen=maxlen, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 50  # we used the 50d embeddings\n",
    "embedding_matrix = np.zeros((len(word2index) + 1, embed_size))\n",
    "\n",
    "for word, i in word2index.items():\n",
    "    embedding_vector = embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313, 50)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Abdulmunim\\Desktop\\Dallol-i Projects\\emojitron\\.venv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        Embedding(input_dim=len(word2index) + 1,\n",
    "                  output_dim=embed_size,\n",
    "                  input_length=maxlen,\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=False\n",
    "                  ),\n",
    "        LSTM(units=16, return_sequences=True),\n",
    "        LSTM(units=4),\n",
    "        Dense(5, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 10, 50)            15650     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 10, 16)            4288      \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 4)                 336       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20299 (79.29 KB)\n",
      "Trainable params: 4649 (18.16 KB)\n",
      "Non-trainable params: 15650 (61.13 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.6035 - accuracy: 0.8780 - val_loss: 1.2940 - val_accuracy: 0.4211\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.6090 - accuracy: 0.8780 - val_loss: 1.2789 - val_accuracy: 0.5789\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.6063 - accuracy: 0.8902 - val_loss: 1.3101 - val_accuracy: 0.6842\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5928 - accuracy: 0.8902 - val_loss: 1.2361 - val_accuracy: 0.5789\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.5952 - accuracy: 0.8902 - val_loss: 1.2105 - val_accuracy: 0.5789\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.5712 - accuracy: 0.9024 - val_loss: 1.2239 - val_accuracy: 0.6316\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.5404 - accuracy: 0.9207 - val_loss: 1.2214 - val_accuracy: 0.5263\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.5728 - accuracy: 0.8841 - val_loss: 1.1927 - val_accuracy: 0.6316\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.5341 - accuracy: 0.9146 - val_loss: 1.2314 - val_accuracy: 0.6842\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.5183 - accuracy: 0.9207 - val_loss: 1.2375 - val_accuracy: 0.5263\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.5087 - accuracy: 0.9146 - val_loss: 1.2448 - val_accuracy: 0.6316\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.4921 - accuracy: 0.9329 - val_loss: 1.2477 - val_accuracy: 0.5789\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.5547 - accuracy: 0.8902 - val_loss: 1.3049 - val_accuracy: 0.5263\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.5042 - accuracy: 0.9329 - val_loss: 1.4035 - val_accuracy: 0.6316\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.4681 - accuracy: 0.9451 - val_loss: 1.3299 - val_accuracy: 0.4737\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4713 - accuracy: 0.9451 - val_loss: 1.3041 - val_accuracy: 0.5263\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4513 - accuracy: 0.9451 - val_loss: 1.2970 - val_accuracy: 0.6316\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.4978 - accuracy: 0.9146 - val_loss: 1.3811 - val_accuracy: 0.4737\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.4737 - accuracy: 0.9390 - val_loss: 1.4405 - val_accuracy: 0.6316\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.5115 - accuracy: 0.9085 - val_loss: 1.3121 - val_accuracy: 0.6316\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4580 - accuracy: 0.9329 - val_loss: 1.3327 - val_accuracy: 0.5263\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4341 - accuracy: 0.9512 - val_loss: 1.3117 - val_accuracy: 0.6316\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4277 - accuracy: 0.9451 - val_loss: 1.2848 - val_accuracy: 0.6316\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.4188 - accuracy: 0.9451 - val_loss: 1.3117 - val_accuracy: 0.5263\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.4065 - accuracy: 0.9573 - val_loss: 1.2942 - val_accuracy: 0.5789\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4044 - accuracy: 0.9512 - val_loss: 1.3409 - val_accuracy: 0.5789\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.3906 - accuracy: 0.9634 - val_loss: 1.3382 - val_accuracy: 0.5263\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.4042 - accuracy: 0.9634 - val_loss: 1.2798 - val_accuracy: 0.6316\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.3865 - accuracy: 0.9634 - val_loss: 1.4715 - val_accuracy: 0.5789\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3915 - accuracy: 0.9512 - val_loss: 1.3757 - val_accuracy: 0.6316\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3741 - accuracy: 0.9573 - val_loss: 1.2791 - val_accuracy: 0.5789\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3626 - accuracy: 0.9756 - val_loss: 1.2503 - val_accuracy: 0.5789\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3588 - accuracy: 0.9756 - val_loss: 1.2693 - val_accuracy: 0.6316\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3558 - accuracy: 0.9695 - val_loss: 1.2992 - val_accuracy: 0.6316\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.3498 - accuracy: 0.9634 - val_loss: 1.2567 - val_accuracy: 0.6316\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.3439 - accuracy: 0.9756 - val_loss: 1.2364 - val_accuracy: 0.6316\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3395 - accuracy: 0.9756 - val_loss: 1.2539 - val_accuracy: 0.6842\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3359 - accuracy: 0.9756 - val_loss: 1.2573 - val_accuracy: 0.6842\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3318 - accuracy: 0.9756 - val_loss: 1.2320 - val_accuracy: 0.6842\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3292 - accuracy: 0.9756 - val_loss: 1.2328 - val_accuracy: 0.6842\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3261 - accuracy: 0.9756 - val_loss: 1.2584 - val_accuracy: 0.6842\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.3222 - accuracy: 0.9756 - val_loss: 1.2541 - val_accuracy: 0.6842\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3187 - accuracy: 0.9756 - val_loss: 1.2643 - val_accuracy: 0.6842\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.3160 - accuracy: 0.9756 - val_loss: 1.2817 - val_accuracy: 0.6842\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.3128 - accuracy: 0.9756 - val_loss: 1.2543 - val_accuracy: 0.6842\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.3101 - accuracy: 0.9756 - val_loss: 1.2568 - val_accuracy: 0.6842\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3072 - accuracy: 0.9756 - val_loss: 1.2666 - val_accuracy: 0.6842\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3046 - accuracy: 0.9756 - val_loss: 1.3066 - val_accuracy: 0.6316\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3173 - accuracy: 0.9695 - val_loss: 1.4144 - val_accuracy: 0.6316\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2861 - accuracy: 0.9817 - val_loss: 1.3064 - val_accuracy: 0.6316\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2804 - accuracy: 0.9817 - val_loss: 1.2882 - val_accuracy: 0.6316\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2907 - accuracy: 0.9756 - val_loss: 1.2342 - val_accuracy: 0.6842\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2779 - accuracy: 0.9817 - val_loss: 1.2720 - val_accuracy: 0.6842\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2805 - accuracy: 0.9756 - val_loss: 1.2526 - val_accuracy: 0.6316\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3429 - accuracy: 0.9451 - val_loss: 1.2915 - val_accuracy: 0.6316\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.3341 - accuracy: 0.9512 - val_loss: 1.3487 - val_accuracy: 0.5789\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6527 - accuracy: 0.8293 - val_loss: 1.2567 - val_accuracy: 0.6842\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.5227 - accuracy: 0.8902 - val_loss: 1.8721 - val_accuracy: 0.5263\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.6809 - accuracy: 0.8110 - val_loss: 1.8365 - val_accuracy: 0.4211\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.4306 - accuracy: 0.9024 - val_loss: 1.2067 - val_accuracy: 0.6316\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4529 - accuracy: 0.9024 - val_loss: 1.2621 - val_accuracy: 0.6316\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3285 - accuracy: 0.9512 - val_loss: 1.5364 - val_accuracy: 0.5789\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3588 - accuracy: 0.9329 - val_loss: 1.4982 - val_accuracy: 0.6316\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2969 - accuracy: 0.9695 - val_loss: 1.3403 - val_accuracy: 0.6316\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2912 - accuracy: 0.9695 - val_loss: 1.2269 - val_accuracy: 0.6316\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2851 - accuracy: 0.9756 - val_loss: 1.2479 - val_accuracy: 0.6842\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2720 - accuracy: 0.9756 - val_loss: 1.3324 - val_accuracy: 0.6316\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2664 - accuracy: 0.9695 - val_loss: 1.4525 - val_accuracy: 0.5789\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2566 - accuracy: 0.9756 - val_loss: 1.2979 - val_accuracy: 0.6842\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2479 - accuracy: 0.9817 - val_loss: 1.2413 - val_accuracy: 0.6842\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2465 - accuracy: 0.9817 - val_loss: 1.2512 - val_accuracy: 0.6842\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2423 - accuracy: 0.9817 - val_loss: 1.2951 - val_accuracy: 0.6842\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2402 - accuracy: 0.9817 - val_loss: 1.3191 - val_accuracy: 0.6842\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2379 - accuracy: 0.9817 - val_loss: 1.2824 - val_accuracy: 0.6842\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2351 - accuracy: 0.9817 - val_loss: 1.2827 - val_accuracy: 0.6842\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2328 - accuracy: 0.9817 - val_loss: 1.2998 - val_accuracy: 0.6842\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.2308 - accuracy: 0.9817 - val_loss: 1.2936 - val_accuracy: 0.6842\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.2234 - accuracy: 0.9817 - val_loss: 1.2624 - val_accuracy: 0.6842\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2192 - accuracy: 0.9817 - val_loss: 1.2641 - val_accuracy: 0.6842\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2190 - accuracy: 0.9817 - val_loss: 1.2810 - val_accuracy: 0.6842\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2127 - accuracy: 0.9817 - val_loss: 1.2453 - val_accuracy: 0.6842\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2112 - accuracy: 0.9817 - val_loss: 1.2425 - val_accuracy: 0.6842\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2094 - accuracy: 0.9817 - val_loss: 1.2456 - val_accuracy: 0.6842\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2071 - accuracy: 0.9817 - val_loss: 1.2673 - val_accuracy: 0.6842\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2051 - accuracy: 0.9817 - val_loss: 1.2685 - val_accuracy: 0.6842\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2034 - accuracy: 0.9817 - val_loss: 1.2672 - val_accuracy: 0.6842\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2014 - accuracy: 0.9817 - val_loss: 1.2766 - val_accuracy: 0.6842\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1997 - accuracy: 0.9817 - val_loss: 1.2828 - val_accuracy: 0.6842\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1983 - accuracy: 0.9817 - val_loss: 1.2859 - val_accuracy: 0.6842\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1967 - accuracy: 0.9817 - val_loss: 1.2723 - val_accuracy: 0.6842\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1953 - accuracy: 0.9817 - val_loss: 1.2904 - val_accuracy: 0.6842\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1936 - accuracy: 0.9817 - val_loss: 1.3148 - val_accuracy: 0.6842\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1919 - accuracy: 0.9817 - val_loss: 1.2993 - val_accuracy: 0.6842\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1904 - accuracy: 0.9817 - val_loss: 1.2913 - val_accuracy: 0.6842\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.1891 - accuracy: 0.9817 - val_loss: 1.2850 - val_accuracy: 0.6842\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1878 - accuracy: 0.9817 - val_loss: 1.3060 - val_accuracy: 0.6842\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1862 - accuracy: 0.9817 - val_loss: 1.3205 - val_accuracy: 0.6842\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.1848 - accuracy: 0.9817 - val_loss: 1.3067 - val_accuracy: 0.6842\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1834 - accuracy: 0.9817 - val_loss: 1.2991 - val_accuracy: 0.6842\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1822 - accuracy: 0.9817 - val_loss: 1.3046 - val_accuracy: 0.6842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2cf95bc0450>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_seq_padded, y_train, epochs=100,\n",
    "          batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"I love you\", \"I feel good\", \"I am hungry\",\n",
    "        \"I am tired\", \"Lets eat together\"]\n",
    "test_seq = tokenizer.texts_to_sequences(test)\n",
    "test_seq_padded = pad_sequences(\n",
    "    test_seq, maxlen=maxlen, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_seq_padded).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love you - ❤️\n",
      "I feel good - 😃\n",
      "I am hungry - 🍽️\n",
      "I am tired - 😃\n",
      "Lets eat together - 🍽️\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test)):\n",
    "    print(f\"{test[i]} - {label_to_emoji(y_pred[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
